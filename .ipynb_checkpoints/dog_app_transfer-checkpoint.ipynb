{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Classifier using Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "          \n",
    "# load filenames for dog images\n",
    "dog_files = np.array(glob(\"dogImages/*/*/*\"))\n",
    "\n",
    "# print number of images in each dataset\n",
    "print('There are %d total dog images.' % len(dog_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vgg16 = models.vgg16(pretrained=True)\n",
    "resnet18= models.resnet18(pretrained=True)\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "squeezenet1_0 = models.squeezenet1_0(pretrained=True)\n",
    "densenet161 = models.densenet161(pretrained=True)\n",
    "inception_v3 = models.inception_v3(pretrained=True)\n",
    "googlenet = models.googlenet(pretrained=True)\n",
    "shufflenet_v2_x1_0 = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "mobilenet_v2 = models.mobilenet_v2(pretrained=True)\n",
    "resnext50_32x4d = models.resnext50_32x4d(pretrained=True)\n",
    "wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)\n",
    "mnasnet1_0 = models.mnasnet1_0(pretrained=True)\n",
    "\n",
    "\n",
    "modelsdict={0: resnet18,\n",
    "            1: alexnet,\n",
    "            2: squeezenet1_0,\n",
    "            3: densenet161,\n",
    "            4: inception_v3,\n",
    "            5: googlenet,\n",
    "            6: shufflenet_v2_x1_0,\n",
    "            7: mobilenet_v2,\n",
    "            8: resnext50_32x4d,\n",
    "            9: wide_resnet50_2,\n",
    "           10:mnasnet1_0}\n",
    "\n",
    "modelsdictnames={0: 'resnet18',\n",
    "            1: 'alexnet',\n",
    "            2: 'squeezenet1_0',\n",
    "            3: 'densenet161',\n",
    "            4: 'inception_v3',\n",
    "            5: 'googlenet',\n",
    "            6: 'shufflenet_v2_x1_0',\n",
    "            7: 'mobilenet_v2',\n",
    "            8: 'resnext50_32x4d',\n",
    "            9: 'wide_resnet50_2',\n",
    "           10: 'mnasnet1_0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define VGG16 model\n",
    "VGG16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    VGG16 = VGG16.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "if os.path.isdir('imagenet1000_clsid_to_human_unix.pkl'):\n",
    "    print('imagenet1000 Classification ID in UNIX-Format already exists!')\n",
    "else:\n",
    "    !python dos2unix.py imagenet1000_clsid_to_human.pkl imagenet1000_clsid_to_human_unix.pkl\n",
    "    print('imagenet1000 Classification ID in UNIX-Format created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('imagenet1000_clsid_to_human_unix.pkl', 'rb')        \n",
    "ImageNetClasses = pickle.load( file )     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Set PIL to be tolerant of image files that are truncated.\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def VGG16_predict(img_path):\n",
    "    '''\n",
    "    Use pre-trained VGG-16 model to obtain index corresponding to \n",
    "    predicted ImageNet class for image at specified path\n",
    "    \n",
    "    Args:\n",
    "        img_path: path to an image\n",
    "        \n",
    "    Returns:\n",
    "        Index corresponding to VGG-16 model's prediction\n",
    "    '''\n",
    "    \n",
    "    ## TODO: Complete the function.\n",
    "    ## Load and pre-process an image from the given img_path\n",
    "    ## Return the *index* of the predicted class for that image\n",
    "    \n",
    "    #taken from https://www.learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/\n",
    "    \n",
    "    #Load\n",
    "    image = Image.open(img_path)\n",
    "    #image.show()  #Check\n",
    "    \n",
    "    #pre-process\n",
    "    #define transformer\n",
    "    transform = transforms.Compose([transforms.Resize(256),\n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    #create transformed image\n",
    "    image_t = transform(image).cuda()\n",
    "    #create batch of images\n",
    "    batch_t = torch.unsqueeze(image_t, 0).cuda()\n",
    "    \n",
    "    VGG16.eval()\n",
    "    out = VGG16(batch_t)\n",
    "    \n",
    "    _, index = torch.max(out, 1)\n",
    "    percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "\n",
    "    #get the index of the best prediction\n",
    "    pred_value_t, pred_index_t = torch.topk(percentage, 1)\n",
    "    \n",
    "    #pred_index_t is a tensor, we need the value (that is the index!)\n",
    "    pred_index=pred_index_t.item()\n",
    "    \n",
    "    return pred_index # predicted class index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowImage(filename):\n",
    "    img = cv2.imread(randomfile)\n",
    "    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do some random visual validation test on VGG16_predict\n",
    "#set the number of tests with NTESTS\n",
    "import random \n",
    "\n",
    "NTEST = 4\n",
    "i = 0\n",
    "while i < NTEST:\n",
    "    randomfile = random.choice(dog_files)\n",
    "    ClassName = ImageNetClasses.get(VGG16_predict(randomfile))\n",
    "    print(\"It is a %s!\" %ClassName)\n",
    "    ShowImage(randomfile)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Specify data loaders\n",
    "\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import torch.utils.data as data\n",
    "\n",
    "### TODO: Write data loaders for training, validation, and test sets\n",
    "## Specify appropriate transforms, and batch_sizes\n",
    "# define train, valid and test data directories\n",
    "dog_dir = 'dogImages'\n",
    "train_dir = os.path.join(dog_dir, 'train/')\n",
    "valid_dir = os.path.join(dog_dir, 'valid/')\n",
    "test_dir = os.path.join(dog_dir, 'test/')\n",
    "# load and transform data\n",
    "RESIZE = 256\n",
    "FSIZE = 224\n",
    "# perform data transform WITH DATA AUGMENTATION for training data\n",
    "train_data_transform = transforms.Compose([transforms.RandomResizedCrop(FSIZE),\n",
    "                                           transforms.RandomHorizontalFlip(),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# perform data transform for valid/test data (NO DATA AUGMENTATION)\n",
    "# we only resize, crop and normalize the valid/test dataset\n",
    "valid_test_data_transform = transforms.Compose([transforms.Resize(RESIZE),\n",
    "                                                transforms.CenterCrop(FSIZE),\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_data_transform)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=valid_test_data_transform)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=valid_test_data_transform)\n",
    "# print out some data stats\n",
    "print('Total num of breeds: ', len(train_data.classes))\n",
    "#N_CLASSES defines the number of outputs of the fully-connected neural network\n",
    "N_CLASSES = len(train_data.classes)\n",
    "\n",
    "print('Num training images: ', len(train_data))\n",
    "print('Num validation images: ', len(valid_data))\n",
    "print('Num test images: ', len(test_data))\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 0\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, \n",
    "                                           batch_size=batch_size, \n",
    "                                           num_workers=num_workers, \n",
    "                                           shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, \n",
    "                                           batch_size=batch_size, \n",
    "                                           num_workers=num_workers,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=batch_size, \n",
    "                                          num_workers=num_workers,\n",
    "                                          shuffle=True)\n",
    "# store all 3 above loaders into a dictionary\n",
    "loaders_transfer = {\n",
    "    'train': train_loader,\n",
    "    'valid': valid_loader,\n",
    "    'test': test_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "## TODO: Specify model architecture \n",
    "\n",
    "model_transfer = models.densenet161(pretrained=True)\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze model weights\n",
    "for param in model_transfer.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model_transfer._modules['features']\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_output = features._modules['norm5']\n",
    "CNN_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model_transfer.classifier.in_features\n",
    "num_ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding custom classifier\n",
    "#How to add , see my comment in\n",
    "#https://discuss.pytorch.org/t/pytorch-transfer-learning-with-densenet/15579/8\n",
    "\n",
    "import torch.nn as nn\n",
    "# Add on classifier\n",
    "n_inputs = num_ftrs  #number inputs given by Densenet-161 Architecture\n",
    "n_classes = 133\n",
    "\n",
    "model_transfer.classifier = nn.Linear(n_inputs, n_classes)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()\n",
    "    print(\"Model transferred to CUDA!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#Try with learning rates {0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001}\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.5\n",
    "NESTEROV = True\n",
    "\n",
    "criterion_transfer = torch.nn.CrossEntropyLoss()\n",
    "optimizer_transfer = torch.optim.SGD(model_transfer.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, nesterov=NESTEROV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESTART = True\n",
    "if RESTART == True:\n",
    "    print('Initializing training!')\n",
    "    #Arrays for plotting training performance\n",
    "    #Avoid re-initialization if training is resumed with again N_EPOCHS!\n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "    valid_loss_min = np.Inf \n",
    "else:\n",
    "    print('Resuming training!')\n",
    "    model_transfer.load_state_dict(torch.load('model_transfer.pt'))\n",
    "    valid_loss_min = loadvalidlossmin('transfer_lossmin.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce\n",
    "# Find total parameters and trainable parameters\n",
    "# With this verify that the Convolutional Network is not going to be retrained!\n",
    "total_params = sum(p.numel() for p in model_transfer.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model_transfer.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "# the following import is required for training to be robust to truncated images\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    \n",
    "    global valid_loss_min\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    " \n",
    "            #Reset gradients to zero in order not to accumulate throughout the batches.\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            \n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            \n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            \n",
    "            #calculate the train_loss_history (not cummulated)\n",
    "            train_loss_history.append(loss.item())\n",
    "            #calculate the train_loss (cummulated)\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            \n",
    "            #Set modulus size to smaller than 300 if you want see some progress in between\n",
    "            #if batch_idx % 20000 == 0:\n",
    "            #    print('Epoch %d, Batch %d training loss: %.6f' %\n",
    "            #      (epoch, batch_idx + 1, train_loss))\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "             # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            valid_loss_history.append(loss.item())\n",
    "            \n",
    "            # update average validation loss \n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss        \n",
    "            savevalidlossmin('transfer_lossmin.p',valid_loss_min)\n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# train the model\n",
    "N_EPOCHS = 20\n",
    "\n",
    "\n",
    "model_transfer = train(N_EPOCHS, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model_transfer.load_state_dict(torch.load('model_transfer.pt'))\n",
    "\n",
    "#Results after 20 Epochs, converging extremely fast!\n",
    "#Question: Why is the validation loss around 40-60% lower than the training loss? \n",
    "#Underfitting – Validation and training error high\n",
    "#Overfitting – Validation error is high, training error low\n",
    "#Good fit – Validation error low, slightly higher than the training error\n",
    "#Unknown fit - Validation error low, training error 'high'\n",
    "#Source: https://stats.stackexchange.com/questions/187335/validation-error-less-than-training-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model that got the best validation accuracy (uncomment the line below)\n",
    "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy paste from model_scratch\n",
    "test_loss_history = []\n",
    "\n",
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        test_loss_history.append(loss.item())\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "    \n",
    "    \n",
    "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Write a function that takes a path to an image as input\n",
    "### and returns the dog breed that is predicted by the model.\n",
    "\n",
    "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
    "#class_names = [item[4:].replace(\"_\", \" \") for item in data_transfer['train'].classes]\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Set PIL to be tolerant of image files that are truncated.\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def predict_breed_transfer(img_path):\n",
    "    '''\n",
    "    Use pre-trained Densenet-161 model to obtain index corresponding to \n",
    "    predicted ImageNet class for image at specified path\n",
    "    \n",
    "    Args:\n",
    "        img_path: path to an image\n",
    "        \n",
    "    Returns:\n",
    "        Index corresponding to model_transfer model's prediction\n",
    "    '''\n",
    "    \n",
    "    ## TODO: Complete the function.\n",
    "    ## Load and pre-process an image from the given img_path\n",
    "    ## Return the *index* of the predicted class for that image\n",
    "    \n",
    "    #Load\n",
    "    image = Image.open(img_path)\n",
    "    \n",
    "    #pre-process\n",
    "    #define transformer\n",
    "    transform = transforms.Compose([transforms.Resize(256),\n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    #create transformed image\n",
    "    image_t = transform(image).cuda()\n",
    "    #create batch of images\n",
    "    batch_t = torch.unsqueeze(image_t, 0).cuda()\n",
    "    \n",
    "    model_transfer.eval()\n",
    "    out = model_transfer(batch_t)\n",
    "    \n",
    "    _, index = torch.max(out, 1)\n",
    "    percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "\n",
    "    #get the index of the best prediction\n",
    "    pred_value_t, pred_index_t = torch.topk(percentage, 1)\n",
    "    \n",
    "    #pred_index_t is a tensor, we need the value (that is the index!)\n",
    "    pred_index=pred_index_t.item()\n",
    "    \n",
    "    pred_value_t, pred_index_t = torch.topk(percentage, 5)\n",
    "    \n",
    "    return pred_index, pred_value_t, pred_index_t  # predicted class index plus topk-5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/elenab/project-dog-breed-classifier/blob/master/dog_app.ipynb\n",
    "def image_to_tensor(img_path):\n",
    "    '''\n",
    "    As per Pytorch documentations: All pre-trained models expect input images normalized in the same way, \n",
    "    i.e. mini-batches of 3-channel RGB images\n",
    "    of shape (3 x H x W), where H and W are expected to be at least 224. \n",
    "    The images have to be loaded in to a range of [0, 1] and \n",
    "    then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. \n",
    "    You can use the following transform to normalize:\n",
    "    '''\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    transformations = transforms.Compose([transforms.Resize(size=224),\n",
    "                                          transforms.CenterCrop((224,224)),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                              std=[0.229, 0.224, 0.225])])\n",
    "    image_tensor = transformations(img)[:3,:,:].unsqueeze(0)\n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "# helper function for un-normalizing an image  - from STYLE TRANSFER exercise\n",
    "# and converting it from a Tensor image to a NumPy image for display\n",
    "def im_convert(tensor):\n",
    "    \"\"\" Display a tensor as an image. \"\"\"\n",
    "    \n",
    "    image = tensor.to(\"cpu\").clone().detach()\n",
    "    image = image.numpy().squeeze()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n",
    "    image = image.clip(0, 1)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I cannot use this one:\n",
    "#class_names = [item[4:].replace(\"_\", \" \") for item in  image_datasets['train'].classes]\n",
    "\n",
    "class_names = [item[4:].replace(\"_\", \" \") for item in  test_data.classes]\n",
    "\n",
    "def predict_breed_transfer(img_path):\n",
    "    # load the image and return the predicted breed\n",
    "    image_tensor = image_to_tensor(img_path)\n",
    "\n",
    "    # move model inputs to cuda, if GPU available\n",
    "    if use_cuda:\n",
    "        image_tensor = image_tensor.cuda()\n",
    "\n",
    "    # get sample outputs\n",
    "    output = model_transfer(image_tensor)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "\n",
    "    pred = np.squeeze(preds_tensor.numpy()) if not use_cuda else np.squeeze(preds_tensor.cpu().numpy())\n",
    "\n",
    "    return class_names[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(img_path, title=\"Title\"):\n",
    "    image = Image.open(img_path)\n",
    "    plt.title(title)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Try out the function\n",
    "for image in random.sample(list(dog_files_short), 10): \n",
    "    predicted_breed = predict_breed_transfer(image)\n",
    "\n",
    "    print('Groundtruth: '+str(image))\n",
    "    display_image(image, title=f\"Predicted:{predicted_breed}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Write your algorithm.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "def run_app(img_path):\n",
    "    ## handle cases for a human face, dog, and neither\n",
    "    if face_detector(img_path):\n",
    "        print('Hey, you are a human!')\n",
    "        display_image(img_path, title='image with a human')\n",
    "    elif predict_breed_transfer(img_path):\n",
    "        print('Hey puppy!')\n",
    "        predicted_breed = predict_breed_transfer(img_path)\n",
    "        display_image(img_path, title=f\"Predicted:{predicted_breed}\")        \n",
    "    else:\n",
    "        print('I have no clue what you are!')\n",
    "        display_image(img_path, title=\"what are you?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
